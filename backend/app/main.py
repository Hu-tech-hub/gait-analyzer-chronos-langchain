from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from langserve import add_routes
import pandas as pd
import numpy as np
import io
import logging
from typing import Dict, List
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

from app.config import settings
from app.models.schemas import UploadResponse, DiagnosisRequest, DiagnosisResponse, ChannelDiagnosis
from app.services.csv_processor import CSVProcessor
from app.services.chronos_embedder import ChronosEmbedder
from app.services.rag_service import RAGService
from app.services.diagnosis_chain import DiagnosisChain
from app.utils.db_client import get_supabase_client

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ì„¼ì„œ ì§„ë‹¨ ì‹œìŠ¤í…œ",
    debug=True,
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
try:
    supabase = get_supabase_client()
    embedder = ChronosEmbedder(settings.CHRONOS_MODEL, settings.DEVICE)
    rag_service = RAGService(supabase)
    diagnosis_chain = DiagnosisChain(settings.OPENAI_API_KEY)
    logger.info("Services initialized successfully")
except Exception as e:
    logger.error(f"Error initializing services: {str(e)}")
    raise

@app.post("/upload_csv", response_model=UploadResponse)
async def upload_csv(file: UploadFile = File(...)):
    """CSV íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬"""
    try:
        # CSV ì½ê¸°
        contents = await file.read()
        df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        
        # ìœ íš¨ì„± ê²€ì¦
        is_valid, message = CSVProcessor.validate_sensor_data(df)
        if not is_valid:
            raise HTTPException(status_code=400, detail=message)
            
        # ì „ì²˜ë¦¬
        df = CSVProcessor.preprocess_data(df)
        
        # DBì— ì›ë³¸ ì €ì¥
        sensor_data = supabase.table('sensor_data').insert({
            "filename": file.filename,
            "row_count": len(df),
            "channel_count": 6,
            "raw_data": df.to_dict('records'),
            "status": "processing"
        }).execute()
        
        sensor_data_id = sensor_data.data[0]['id']
        
        # ì„ë² ë”© ìƒì„±
        embeddings = embedder.process_sensor_data(df)
        
        # ì„ë² ë”© DB ì €ì¥
        for channel, data in embeddings.items():
            supabase.table('embeddings').insert({
                "sensor_data_id": sensor_data_id,
                "channel_name": channel,
                "embedding": data["embedding"].tolist(),
                "mean_value": data["stats"]["mean"],
                "variance": data["stats"]["variance"],
                "peak_value": data["stats"]["peak"],
                "min_value": data["stats"]["min"],
                "outlier_count": data["stats"]["outlier_count"],
                "zero_crossing_rate": data["stats"]["zero_crossing_rate"]
            }).execute()
            
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        supabase.table('sensor_data').update({
            "status": "completed"
        }).eq('id', sensor_data_id).execute()
        
        return UploadResponse(
            sensor_data_id=sensor_data_id,
            filename=file.filename,
            row_count=len(df),
            channel_count=6,
            status="completed"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/diagnosis", response_model=DiagnosisResponse)
async def create_diagnosis(request: DiagnosisRequest):
    """ì§„ë‹¨ ìƒì„±"""
    try:
        logger.debug(f"Processing diagnosis request for sensor_data_id: {request.sensor_data_id}")
        
        # 1. ì„¼ì„œ ë°ì´í„°ì˜ ì„ë² ë”© ì¡°íšŒ
        embeddings_data = supabase.table('embeddings').select("*").eq(
            'sensor_data_id', request.sensor_data_id
        ).execute()
        
        logger.debug(f"Found {len(embeddings_data.data)} embeddings")

        if not embeddings_data.data:
            raise HTTPException(
                status_code=404,
                detail=f"No embeddings found for sensor_data_id: {request.sensor_data_id}"
            )
        
        # 2. ì„ë² ë”©ê³¼ í†µê³„ ë°ì´í„° êµ¬ì„±
        sensor_embeddings = {}
        sensor_stats = {}
        
        for emb in embeddings_data.data:
            channel = emb['channel_name']
            # ë¬¸ìì—´ ì„ë² ë”©ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
            if isinstance(emb['embedding'], str):
                embedding_str = emb['embedding'].strip('[]')
                embedding_list = [float(x) for x in embedding_str.split(',')]
                embedding_vector = np.array(embedding_list, dtype=np.float32)
            else:
                embedding_vector = np.array(emb['embedding'], dtype=np.float32)
                
            sensor_embeddings[channel] = embedding_vector
            sensor_stats[channel] = {
                'mean': emb['mean_value'],
                'variance': emb['variance'],
                'peak': emb['peak_value'],
                'outlier_count': emb['outlier_count'],
                'zero_crossing_rate': emb['zero_crossing_rate']
            }
            
        logger.debug(f"Processed embeddings for channels: {list(sensor_embeddings.keys())}")
        
        # 3. RAGë¥¼ í†µí•œ ì§„ë‹¨ íŒ¨í„´ ê²€ìƒ‰
        matched_diagnoses = rag_service.search_diagnosis(
            sensor_embeddings, 
            threshold=10.0
        )
        
        logger.debug(f"Found {len(matched_diagnoses)} matching diagnoses")

        if not matched_diagnoses:
            raise HTTPException(
                status_code=404,
                detail="No matching diagnosis patterns found"
            )
        
        # 4. ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
        if embeddings_data.data:
            try:
                rag_service.log_search_results(
                    embeddings_data.data[0]['id'],
                    matched_diagnoses
                )
            except Exception as e:
                print(f"Warning: Failed to log search results: {str(e)}")
        
        # ê° ì¶•ë³„ ìœ ì‚¬ ì„ë² ë”© ê²€ìƒ‰
        similar_channels = []
        for emb in embeddings_data.data:
            channel = emb['channel_name']
            similar = rag_service.search_similar(
                emb['embedding'],  # ë¬¸ìì—´ í˜•íƒœì˜ ì„ë² ë”©ì„ ì§ì ‘ ì „ë‹¬
                threshold=80.0
            )
            if similar:
                similar_channels.extend(similar)
                
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = diagnosis_chain.create_system_prompt(similar_channels, sensor_stats)
        
        # 6. GPTë¥¼ í†µí•œ ì¢…í•© ì§„ë‹¨ ìƒì„±
        diagnosis = diagnosis_chain.generate_diagnosis(system_prompt)
        
        # 7. ê° ì±„ë„ë³„ ì§„ë‹¨ êµ¬ì„±
        channel_diagnoses = []
        for diag in matched_diagnoses[:6]:  # ìƒìœ„ 6ê°œë§Œ
            channel_diagnoses.append(ChannelDiagnosis(
                channel=diag['channel'],
                diagnosis=diag['diagnosis_text'],
                statistics=sensor_stats.get(diag['channel'], {}),
                severity=diag['severity'],
                similarity=diag['similarity']  # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ê°€
            ))
        
        # 8. ì§„ë‹¨ ê²°ê³¼ DB ì €ì¥
        try:
            diagnosis_result = supabase.table('diagnosis').insert({
                "sensor_data_id": request.sensor_data_id,
                "user_id": request.user_id,
                "overall_diagnosis": diagnosis["overall_diagnosis"],
                "severity_level": diagnosis["severity_level"],
                "recommendations": diagnosis["recommendations"],
                "used_embeddings": matched_diagnoses,
                "system_prompt": system_prompt,
                
                # ê° ì¶•ë³„ ì§„ë‹¨ ì €ì¥
                "accx_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'AccX'), None),
                "accy_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'AccY'), None),
                "accz_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'AccZ'), None),
                "gyrx_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'GyrX'), None),
                "gyry_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'GyrY'), None),
                "gyrz_diagnosis": next((d['diagnosis_text'] for d in matched_diagnoses if d['channel'] == 'GyrZ'), None),
            }).execute()
        except Exception as e:
            print(f"Warning: Failed to save diagnosis result: {str(e)}")
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ì‘ë‹µì€ ë°˜í™˜
            return DiagnosisResponse(
                diagnosis_id=None,  # DB ì €ì¥ ì‹¤íŒ¨
                sensor_data_id=request.sensor_data_id,
                channel_diagnoses=channel_diagnoses,
                overall_diagnosis=diagnosis["overall_diagnosis"],
                severity_level=diagnosis["severity_level"],
                recommendations=diagnosis["recommendations"],
                created_at=None
            )
        
        return DiagnosisResponse(
            diagnosis_id=diagnosis_result.data[0]['id'],
            sensor_data_id=request.sensor_data_id,
            channel_diagnoses=channel_diagnoses,
            overall_diagnosis=diagnosis["overall_diagnosis"],
            severity_level=diagnosis["severity_level"],
            recommendations=diagnosis["recommendations"],
            created_at=diagnosis_result.data[0]['created_at']
        )
        
    except HTTPException as he:
        raise he
    except Exception as e:
        print(f"Error in create_diagnosis: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.get("/sensor_data")
async def get_sensor_data():
    """ì—…ë¡œë“œëœ ì„¼ì„œ ë°ì´í„° ëª©ë¡ ì¡°íšŒ"""
    try:
        response = supabase.table('sensor_data').select("*").order('upload_time', desc=True).limit(10).execute()
        
        # ì‘ë‹µ ë°ì´í„° ê°€ê³µ
        sensor_data_list = []
        for data in response.data:
            sensor_data_list.append({
                "id": data["id"],
                "filename": data["filename"],
                "created_at": data["upload_time"],
                "status": data["status"],
                "row_count": data["row_count"]
            })
            
        return sensor_data_list
        
    except Exception as e:
        logger.error(f"Error fetching sensor data: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch sensor data: {str(e)}"
        )

# Uvicornìœ¼ë¡œ ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    print(f"\nğŸš€ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“Œ ì£¼ì†Œ: http://{settings.HOST}:{settings.PORT}")
    print(f"ğŸ“– API ë¬¸ì„œ: http://{settings.HOST}:{settings.PORT}/docs")
    print(f"ğŸ›‘ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
    
    uvicorn.run(
        "app.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=True  # ê°œë°œ ì¤‘ ìë™ ì¬ì‹œì‘
    )